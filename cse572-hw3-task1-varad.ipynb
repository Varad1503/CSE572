{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7969299,"sourceType":"datasetVersion","datasetId":4689085}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CSE 572: Data Mining \n## Homework 3 Task 1\n## Varad Vijay Deshmukh\n## 1225369184","metadata":{}},{"cell_type":"markdown","source":"### Task 1 Algorithmic Analysis K-Means Clustering with Real World Dataset","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics.pairwise import pairwise_distances","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:10.008261Z","iopub.execute_input":"2024-03-29T17:14:10.008745Z","iopub.status.idle":"2024-03-29T17:14:12.878455Z","shell.execute_reply.started":"2024-03-29T17:14:10.008706Z","shell.execute_reply":"2024-03-29T17:14:12.876977Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:16.230342Z","iopub.execute_input":"2024-03-29T17:14:16.231067Z","iopub.status.idle":"2024-03-29T17:14:16.237878Z","shell.execute_reply.started":"2024-03-29T17:14:16.231017Z","shell.execute_reply":"2024-03-29T17:14:16.235968Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = np.array(pd.read_csv('/kaggle/input/k-means-data/data.csv', header=None))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:19.641862Z","iopub.execute_input":"2024-03-29T17:14:19.642345Z","iopub.status.idle":"2024-03-29T17:14:20.854262Z","shell.execute_reply.started":"2024-03-29T17:14:19.642309Z","shell.execute_reply":"2024-03-29T17:14:20.852943Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"labels = np.ravel(pd.read_csv('/kaggle/input/k-means-data/label.csv', header=None))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:24.306033Z","iopub.execute_input":"2024-03-29T17:14:24.306431Z","iopub.status.idle":"2024-03-29T17:14:24.318519Z","shell.execute_reply.started":"2024-03-29T17:14:24.306401Z","shell.execute_reply":"2024-03-29T17:14:24.317399Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\nprint(labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:27.208183Z","iopub.execute_input":"2024-03-29T17:14:27.209184Z","iopub.status.idle":"2024-03-29T17:14:27.215857Z","shell.execute_reply.started":"2024-03-29T17:14:27.209145Z","shell.execute_reply":"2024-03-29T17:14:27.214619Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(10000, 784)\n(10000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Q1: Run K-means clustering with Euclidean, Cosine and Jarcard similarity. Specify K= the**\n**number of categorical values of y (the number of classifications). Compare the SSEs of** \n**Euclidean-K-means, Cosine-K-means, Jarcard-K-means. Which method is better?**","metadata":{}},{"cell_type":"code","source":"class KMeansClustering:\n    \n    def __init__(self, k, stopping_criterion=\"no_change\") -> None:\n        self.k = k\n        self.stopping_criterion = stopping_criterion\n        self.centroids = None\n        self._sse_score = None\n        self._last_sse_score = float('inf')\n        self._iterations = 0\n\n    def euclidean_distance(self, data_point, centroids):\n        return np.sqrt(np.sum((centroids - data_point)**2, axis=1))\n\n    def __sum_of_squared_errors_calc(self, centroids, data, y):\n        sum_of_errors = 0.0\n        for idx, d in enumerate(data):\n            sum_of_errors += np.sum((centroids[y[idx]] - d) ** 2)\n\n        return sum_of_errors\n\n    def get_sum_of_squared_error(self):\n        return self._sse_score\n    def get_iterations_to_converge(self):\n        return self._iterations\n    \n    def fit(self, X, max_iterations=200):\n        self.centroids = np.random.uniform(\n            low=np.amin(X, axis=0),\n            high=np.amax(X, axis=0),\n            size=(self.k, X.shape[1]))\n        y = []\n        for _ in range(max_iterations):\n            y = []\n            for data_point in X:\n                distances = self.euclidean_distance(data_point=data_point,centroids=self.centroids)\n                cluster_num = np.argmin(distances)\n                y.append(cluster_num)\n            y = np.asarray(y)\n            cluster_indices = []\n            for idx in range(self.k):\n                cluster_indices.append(np.argwhere(y == idx))\n            cluster_centers = []\n            for i, indices in enumerate(cluster_indices):\n                if len(indices) == 0:\n                    cluster_centers.append(self.centroids[i])\n                else:\n                    cluster_centers.append(np.mean(X[indices], axis=0)[0])\n            if self.stopping_criterion == \"no_change\" and np.max(self.centroids - np.array(cluster_centers)) < 1e-3:\n                break\n            elif self.stopping_criterion == \"increase_sse\":\n                current_sse = self.__sum_of_squared_errors_calc(X, np.array(cluster_centers), y)\n                if current_sse > self._last_sse_score:\n                    break\n                self._last_sse_score = current_sse\n            else:\n                self.centroids = np.array(cluster_centers)\n            self._iterations += 1\n        self._sse_score = self.__sum_of_squared_errors_calc(X, self.centroids, y)\n        return y   \n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:15:23.994736Z","iopub.execute_input":"2024-03-29T17:15:23.995137Z","iopub.status.idle":"2024-03-29T17:15:24.015596Z","shell.execute_reply.started":"2024-03-29T17:15:23.995107Z","shell.execute_reply":"2024-03-29T17:15:24.013900Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class KMeansClustering:\n    \n    def __init__(self, k, stopping_criterion=\"no_change\") -> None:\n        self.k = k\n        self.stopping_criterion = stopping_criterion\n        self.centroids = None\n        self._sse_score = None\n        self._last_sse_score = float('inf')\n        self._iterations = 0\n\n    def euclidean_distance(data_point, centroids):\n        return np.sqrt(np.sum((centroids - data_point) ** 2, axis=1))\n\n    def _sum_of_squared_errors(self, data, assignments):\n        return sum(np.sum((self.centroids[cluster] - data[point_idx]) ** 2)\n                   for point_idx, cluster in enumerate(assignments))\n\n    def get_sum_of_squared_error(self):\n        return self._sse_score\n\n    def get_iterations_to_converge(self):\n        return self._iterations\n    \n    def fit(self, X, max_iterations=200):\n        self.centroids = np.random.uniform(low=np.amin(X, axis=0), high=np.amax(X, axis=0), size=(self.k, X.shape[1]))\n\n        for _ in range(max_iterations):\n            distances = np.array([self.euclidean_distance(data_point, self.centroids) for data_point in X])\n            assignments = np.argmin(distances, axis=1)\n            new_centroids = np.array([X[assignments == k].mean(axis=0) if len(X[assignments == k]) > 0 else self.centroids[k] \n                                      for k in range(self.k)])\n            if self.stopping_criterion == \"no_change\" and np.allclose(self.centroids, new_centroids, atol=1e-3):\n                #print(\"breaking -check\")\n                break\n            elif self.stopping_criterion == \"increase_sse\":\n                current_sse = self._sum_of_squared_errors(X, assignments)\n                if current_sse > self._last_sse_score:\n                    break\n                self._last_sse_score = current_sse\n            self.centroids = new_centroids\n            self._iterations += 1\n        self._sse_score = self._sum_of_squared_errors(X, assignments)\n        return assignments\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:31.274103Z","iopub.execute_input":"2024-03-29T17:14:31.274578Z","iopub.status.idle":"2024-03-29T17:14:31.290986Z","shell.execute_reply.started":"2024-03-29T17:14:31.274545Z","shell.execute_reply":"2024-03-29T17:14:31.289979Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"unique_labels = np.unique(labels)\nno_of_clusters = unique_labels.size\nMAX_ITERATIONS = 100","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:14:43.476156Z","iopub.execute_input":"2024-03-29T17:14:43.477011Z","iopub.status.idle":"2024-03-29T17:14:43.483895Z","shell.execute_reply.started":"2024-03-29T17:14:43.476969Z","shell.execute_reply":"2024-03-29T17:14:43.482289Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Q2: Compare the accuracies of Euclidean-K-means Cosine-K-means, Jarcard-K-means. First,** \n**label each cluster using the majority vote label of the data points in that cluster. Later, compute**\n**the predictive accuracy of Euclidean-K-means, Cosine-K-means, Jarcard-K-means. Which metric** \n**is better?**","metadata":{}},{"cell_type":"markdown","source":"First Running Euclidean K-means","metadata":{}},{"cell_type":"code","source":"euclidean_kmeans_m = KMeansClustering(k=no_of_clusters)\neuclidean_kmeans_m_labels = euclidean_kmeans_m.fit(X=data, max_iterations=MAX_ITERATIONS)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:15:28.097406Z","iopub.execute_input":"2024-03-29T17:15:28.097869Z","iopub.status.idle":"2024-03-29T17:15:48.128531Z","shell.execute_reply.started":"2024-03-29T17:15:28.097837Z","shell.execute_reply":"2024-03-29T17:15:48.127161Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sse_euclidean_m = euclidean_kmeans_m.get_sum_of_squared_error()\nsse_euclidean_m","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:28:09.428177Z","iopub.execute_input":"2024-03-29T17:28:09.428663Z","iopub.status.idle":"2024-03-29T17:28:09.437171Z","shell.execute_reply.started":"2024-03-29T17:28:09.428628Z","shell.execute_reply":"2024-03-29T17:28:09.435829Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"38844445.13351093"},"metadata":{}}]},{"cell_type":"markdown","source":"Second Running Cosine K-means","metadata":{}},{"cell_type":"code","source":"cosine_distances = pairwise_distances(data, metric='cosine')\ncosine_kmeans_m = KMeansClustering(k=no_of_clusters)\ncosine_kmeans_m_labels = cosine_kmeans_m.fit(cosine_distances, max_iterations=MAX_ITERATIONS)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:16:25.648247Z","iopub.execute_input":"2024-03-29T17:16:25.648700Z","iopub.status.idle":"2024-03-29T17:18:16.331674Z","shell.execute_reply.started":"2024-03-29T17:16:25.648664Z","shell.execute_reply":"2024-03-29T17:18:16.330403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sse_cosine_m = cosine_kmeans_m.get_sum_of_squared_error()\nsse_cosine_m","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:28:22.398327Z","iopub.execute_input":"2024-03-29T17:28:22.399808Z","iopub.status.idle":"2024-03-29T17:28:22.407807Z","shell.execute_reply.started":"2024-03-29T17:28:22.399752Z","shell.execute_reply":"2024-03-29T17:28:22.406141Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"5197.394291485597"},"metadata":{}}]},{"cell_type":"markdown","source":"Third Running Jarcard K-means","metadata":{}},{"cell_type":"code","source":"jaccard_distances = pairwise_distances(data, metric='hamming')\njaccard_kmeans_m = KMeansClustering(k=no_of_clusters)\njaccard_kmeans_m_labels = jaccard_kmeans_m.fit(X=jaccard_distances, max_iterations=MAX_ITERATIONS)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:21:24.129138Z","iopub.execute_input":"2024-03-29T17:21:24.129614Z","iopub.status.idle":"2024-03-29T17:23:53.417892Z","shell.execute_reply.started":"2024-03-29T17:21:24.129581Z","shell.execute_reply":"2024-03-29T17:23:53.416451Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"sse_jaccard_m = jaccard_kmeans_m.get_sum_of_squared_error()\nsse_jaccard_m","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:33:04.841191Z","iopub.execute_input":"2024-03-29T17:33:04.841611Z","iopub.status.idle":"2024-03-29T17:33:04.849604Z","shell.execute_reply.started":"2024-03-29T17:33:04.841579Z","shell.execute_reply":"2024-03-29T17:33:04.848495Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1715.5309788799525"},"metadata":{}}]},{"cell_type":"code","source":"print(\"SSE of Euclidean K-means:\", sse_euclidean_m,\"\\tSSE of Cosine K-means:\", sse_cosine_m ,\"\\tSSE of Jarcard K-means:\", sse_jaccard_m)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:33:32.551195Z","iopub.execute_input":"2024-03-29T17:33:32.551729Z","iopub.status.idle":"2024-03-29T17:33:32.559369Z","shell.execute_reply.started":"2024-03-29T17:33:32.551692Z","shell.execute_reply":"2024-03-29T17:33:32.557847Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"SSE of Euclidean K-means: 38844445.13351093 \tSSE of Cosine K-means: 5197.394291485597 \tSSE of Jarcard K-means: 1715.5309788799525\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Q3: Set up the same stop criteria: “when there is no change in centroid position OR when the**\n**SSE value increases in the next iteration OR when the maximum preset value (e.g., 500, you**\n**can set the preset value by yourself) of iteration is complete”, for Euclidean-K-means, Cosine-K\u0002means, Jarcard-K-means. Which method requires more** **iterations and times to converge?**","metadata":{}},{"cell_type":"code","source":"euclidean_iterations = euclidean_kmeans_m.get_iterations_to_converge()\neuclidean_iterations","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:55:14.438688Z","iopub.execute_input":"2024-03-29T17:55:14.439128Z","iopub.status.idle":"2024-03-29T17:55:14.449022Z","shell.execute_reply.started":"2024-03-29T17:55:14.439098Z","shell.execute_reply":"2024-03-29T17:55:14.447220Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"45"},"metadata":{}}]},{"cell_type":"code","source":"cosine_iterations = cosine_kmeans_m.get_iterations_to_converge()\ncosine_iterations","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:55:38.963206Z","iopub.execute_input":"2024-03-29T17:55:38.963695Z","iopub.status.idle":"2024-03-29T17:55:38.971760Z","shell.execute_reply.started":"2024-03-29T17:55:38.963659Z","shell.execute_reply":"2024-03-29T17:55:38.970626Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"45"},"metadata":{}}]},{"cell_type":"code","source":"jaccard_iterations = jaccard_kmeans_m.get_iterations_to_converge()\njaccard_iterations","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:56:51.974957Z","iopub.execute_input":"2024-03-29T17:56:51.976810Z","iopub.status.idle":"2024-03-29T17:56:51.986265Z","shell.execute_reply.started":"2024-03-29T17:56:51.976763Z","shell.execute_reply":"2024-03-29T17:56:51.984812Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"markdown","source":"**Q4: Compare the SSEs of Euclidean-K-means Cosine-K-means, Jarcard-K-means with respect to \nthe following three terminating conditions:**\n\n**• when there is no change in centroid position**\n\n**• when the SSE value increases in the next iteration**\n\n**• when the maximum preset value (e.g., 100) of iteration is complete**","metadata":{}},{"cell_type":"code","source":"euclidean_kmeans_no_change = KMeansClustering(k=no_of_clusters, stopping_criterion=\"no_change\")\neuclidean_kmeans_no_change_predicted_labels = euclidean_kmeans_no_change.fit(data, max_iterations=MAX_ITERATIONS)\nsse_euclidean_kmeans_no_change = euclidean_kmeans_no_change.get_sum_of_squared_error()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:26:33.702822Z","iopub.execute_input":"2024-03-29T18:26:33.704237Z","iopub.status.idle":"2024-03-29T18:26:55.647997Z","shell.execute_reply.started":"2024-03-29T18:26:33.704184Z","shell.execute_reply":"2024-03-29T18:26:55.646684Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"sse_euclidean_kmeans_no_change","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:28:42.570746Z","iopub.execute_input":"2024-03-29T18:28:42.571540Z","iopub.status.idle":"2024-03-29T18:28:42.580652Z","shell.execute_reply.started":"2024-03-29T18:28:42.571495Z","shell.execute_reply":"2024-03-29T18:28:42.579307Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"36068621.54900269"},"metadata":{}}]},{"cell_type":"code","source":"cosine_kmeans_no_change = KMeansClustering(k=no_of_clusters, stopping_criterion=\"no_change\")\ncosine_kmeans_no_change_predicted_labels = cosine_kmeans_no_change.fit(cosine_distances, max_iterations=MAX_ITERATIONS)\nsse_cosine_kmeans_no_change = cosine_kmeans_no_change.get_sum_of_squared_error()\nsse_cosine_kmeans_no_change","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:29:51.200020Z","iopub.execute_input":"2024-03-29T18:29:51.200521Z","iopub.status.idle":"2024-03-29T18:31:15.395246Z","shell.execute_reply.started":"2024-03-29T18:29:51.200484Z","shell.execute_reply":"2024-03-29T18:31:15.393787Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"5687.529253065356"},"metadata":{}}]},{"cell_type":"code","source":"jaccard_kmeans_no_change = KMeansClustering(k=no_of_clusters, stopping_criterion=\"no_change\")\njaccard_kmeans_no_change_predicted_labels = jaccard_kmeans_no_change.fit(jaccard_distances, max_iterations=MAX_ITERATIONS)\nsse_jaccard_kmeans_no_change = jaccard_kmeans_no_change.get_sum_of_squared_error()\nsse_jaccard_kmeans_no_change","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:32:26.044792Z","iopub.execute_input":"2024-03-29T18:32:26.045265Z","iopub.status.idle":"2024-03-29T18:32:40.667281Z","shell.execute_reply.started":"2024-03-29T18:32:26.045231Z","shell.execute_reply":"2024-03-29T18:32:40.666039Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"1740.6843471345078"},"metadata":{}}]},{"cell_type":"code","source":"euclidean_kmeans_increase = KMeansClustering(k=no_of_clusters, stopping_criterion=\"increase_sse\")\neuclidean_kmeans_increase_predicted_labels = euclidean_kmeans_increase.fit(data, max_iterations=MAX_ITERATIONS)\nsse_euclidean_kmeans_increase = euclidean_kmeans_increase.get_sum_of_squared_error()","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:34:38.354522Z","iopub.execute_input":"2024-03-29T18:34:38.355644Z","iopub.status.idle":"2024-03-29T18:35:20.090807Z","shell.execute_reply.started":"2024-03-29T18:34:38.355601Z","shell.execute_reply":"2024-03-29T18:35:20.089465Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sse_euclidean_kmeans_increase","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:35:37.663266Z","iopub.execute_input":"2024-03-29T18:35:37.664454Z","iopub.status.idle":"2024-03-29T18:35:37.670652Z","shell.execute_reply.started":"2024-03-29T18:35:37.664412Z","shell.execute_reply":"2024-03-29T18:35:37.669520Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"121254183.62086494"},"metadata":{}}]},{"cell_type":"code","source":"cosine_kmeans_increase = KMeansClustering(k=no_of_clusters, stopping_criterion=\"increase_sse\")\ncosine_kmeans_increase_predicted_labels = cosine_kmeans_increase.fit(cosine_distances, max_iterations=MAX_ITERATIONS)\nsse_cosine_kmeans_increase = cosine_kmeans_increase.get_sum_of_squared_error()\nsse_cosine_kmeans_increase","metadata":{"execution":{"iopub.status.busy":"2024-03-29T18:36:46.977662Z","iopub.execute_input":"2024-03-29T18:36:46.978086Z","iopub.status.idle":"2024-03-29T18:40:45.695820Z","shell.execute_reply.started":"2024-03-29T18:36:46.978056Z","shell.execute_reply":"2024-03-29T18:40:45.694882Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"10478.367939108728"},"metadata":{}}]}]}